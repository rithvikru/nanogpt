{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8ce9fb-6b1f-4771-8433-45b1adb52e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d1c29-2701-476c-80c2-c67af2b514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55d69f2-b112-4967-b5ed-899ef0dca8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43bef6a-8e22-4149-b4f1-aac20760a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "decode = lambda l: \"\".join(itos[i] for i in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c41d45c3-43c2-4b41-a769-79931e9fc284",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee11af2b-61c9-460a-a55f-8120d6b8dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d6786fc-00af-4069-a1d5-652946819f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "context_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + context_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + context_size + 1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8a550db-e4aa-4759-8d50-bcd05a57ed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76049, 234249, 934904, 560986])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "xb, yb = get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b140595-9718-4a73-9c6f-a31bb066c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)  # collapse so i can use NLL\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):  # gpt-like streaming\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]  # just get what comes next\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # upd to next token\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0b35dfc0-8753-4109-a484-b9e16e6659cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v?ejUk\n",
      "gWghdAtoWzgTGTqPUfpT\n",
      "vl!bRo TqZFJ-ekQMC.B$Bt$myNdneEEbamGyFhqVT!mzgCngdwMjrXS&\n",
      "ScqbqVCNtsM d;\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "print(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "18a9821f-a1c9-4ad4-a3d3-a81403275c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a391dd58-6d33-4876-b1ef-bec02f1a14fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4384336471557617\n",
      "2.6143569946289062\n",
      "2.5687055587768555\n",
      "2.5410969257354736\n",
      "2.4855878353118896\n",
      "2.4748616218566895\n",
      "2.527994155883789\n",
      "2.388068914413452\n",
      "2.3501267433166504\n",
      "2.491438150405884\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for epoch in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "00f47341-ce90-45e8-ae5e-b8744bfb4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S:\n",
      "Herothin; awin; wh s he worurance me,'s y m thelalfe Henofrcouturyo\n",
      "OUpenkithitof fods me s d, henoume;\n",
      "POR:utout, Frded, m I y's moust omod d LIfr branourrn mshyoues mit here y, fes s st stho thiressissinot:\n",
      "TENondd oury proror whano; be, cthe bore goullllacysshoft st citheasou fed wotispous?\n",
      "\n",
      "LULor gutu f rknooldsef t r tale ng mike souirs\n",
      "TUE:\n",
      "LUEnd vinorersedindicale towilist\n",
      "\n",
      "Fue? achilemoursond, g gh beistheathe f; t EN qu twndertimmy seatlo t h an s olare gen nt\n",
      "SA ptono lie bery thato\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b53752c0-6006-4194-838b-ce5c97c9c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9e25b080-31ce-47f8-95f0-706f112e744c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3491e+00, -1.3778e+00, -4.9704e-01, -6.4773e-01, -6.5595e-01,\n",
       "          -1.7690e-01,  5.7319e-01,  1.6617e+00],\n",
       "         [ 7.7809e-01, -3.6348e-01,  3.6587e-01, -4.0361e-01,  3.8396e-01,\n",
       "          -5.5295e-01, -1.2078e+00,  5.7024e-02],\n",
       "         [-7.9892e-01, -1.9372e-01, -8.7293e-01, -2.1363e-01, -4.7672e-01,\n",
       "           4.5359e-01, -1.0960e+00,  1.0909e+00],\n",
       "         [-2.8941e+00,  3.6250e-01, -1.4500e+00,  1.0103e-01, -8.1625e-01,\n",
       "           3.0137e-01,  1.1132e+00,  1.1987e+00],\n",
       "         [ 1.2419e+00, -2.4641e+00,  3.1948e+00,  1.0834e+00,  1.2745e+00,\n",
       "          -9.0531e-01,  9.6187e-01,  1.1861e+00],\n",
       "         [ 2.4091e+00, -1.5802e+00,  1.3233e+00,  2.2658e-01,  1.5482e+00,\n",
       "          -2.5287e+00,  2.5553e-01, -4.6723e-01],\n",
       "         [-2.7087e+00,  4.3270e-01, -7.7406e-02,  8.3706e-01, -1.5908e-01,\n",
       "           1.2910e+00, -1.0812e+00,  2.2230e+00],\n",
       "         [ 4.3451e-01,  2.1320e-01, -5.7762e-01,  5.3235e-01,  7.6754e-01,\n",
       "          -2.0091e+00,  1.5373e+00, -3.1043e+00]],\n",
       "\n",
       "        [[-1.6139e+00, -1.9314e+00, -4.9069e-01,  5.6850e-01,  2.5678e-01,\n",
       "          -2.7834e+00, -5.0579e-01, -2.0752e+00],\n",
       "         [-1.1158e+00, -1.1370e+00,  4.3724e-02,  7.4244e-01, -4.5821e-01,\n",
       "          -8.6479e-01,  2.7254e-01,  1.5990e-01],\n",
       "         [-2.0904e+00, -2.9936e+00, -1.4177e+00, -1.3283e+00,  2.4018e+00,\n",
       "          -1.7881e+00, -2.2441e-01, -2.3819e+00],\n",
       "         [ 3.6479e-02,  1.2729e+00, -7.5829e-01,  4.5567e-02, -2.2715e+00,\n",
       "          -2.1569e-01, -3.4256e-01,  3.5047e-01],\n",
       "         [-1.0659e+00, -5.2125e-01, -1.5305e+00,  1.4136e-01,  2.0808e+00,\n",
       "          -2.1515e-01, -3.8976e-01, -5.7247e-01],\n",
       "         [ 1.3931e+00, -3.3687e-03,  7.7781e-03,  2.3544e+00, -7.0220e-01,\n",
       "          -6.7715e-01,  8.7111e-01, -3.2821e-01],\n",
       "         [-3.0707e+00, -1.7286e+00, -1.0312e+00, -1.5790e+00,  4.6757e-01,\n",
       "          -4.6557e-01, -1.1135e+00,  3.7054e-01],\n",
       "         [ 1.1693e+00, -4.1086e-01,  3.1192e-01,  1.2767e-01, -2.5719e-01,\n",
       "          -3.4620e-01,  4.2094e-01, -1.1767e+00]],\n",
       "\n",
       "        [[-1.1954e+00, -1.0597e+00,  1.2343e+00,  9.1753e-02, -1.7304e-02,\n",
       "          -2.6042e-01,  1.4679e+00, -2.5177e+00],\n",
       "         [-1.0384e-01,  6.5846e-01,  1.5124e+00, -7.1366e-01,  1.2026e+00,\n",
       "           1.4257e+00,  4.0037e-01, -1.0259e-03],\n",
       "         [ 1.3252e+00,  2.3717e+00,  2.3790e+00,  2.1147e+00,  7.1923e-01,\n",
       "          -4.8887e-01, -2.0412e-01, -7.7833e-01],\n",
       "         [-1.5134e+00, -2.5547e+00,  1.0633e+00, -2.3933e-01, -2.9438e+00,\n",
       "           8.2563e-01,  1.5470e+00,  1.4685e-01],\n",
       "         [ 4.5290e-01,  9.4299e-02,  1.3415e+00,  8.0814e-01, -1.2032e+00,\n",
       "          -1.3299e+00,  2.8892e-01, -1.3714e+00],\n",
       "         [-8.2008e-02, -7.4125e-01, -2.6086e+00, -1.0646e+00, -2.6803e-01,\n",
       "          -1.3061e+00,  7.1071e-01,  2.6335e-01],\n",
       "         [-1.1599e+00, -1.2443e+00, -1.9189e+00,  1.2434e+00, -1.9498e+00,\n",
       "          -2.4009e+00, -7.7725e-01,  1.3956e+00],\n",
       "         [-4.7116e-01, -1.2535e+00,  2.0415e-01, -1.2811e+00, -1.0641e+00,\n",
       "          -5.5578e-01,  2.5790e+00, -1.7562e+00]],\n",
       "\n",
       "        [[ 2.9271e-01, -1.3035e+00, -1.4167e+00,  1.6118e-01, -5.6141e-01,\n",
       "          -1.6701e+00,  1.5265e+00, -2.0421e+00],\n",
       "         [-8.0442e-01,  1.4503e-02,  3.2964e-01, -4.4385e-01,  1.3515e-01,\n",
       "          -9.9084e-01, -1.8686e-01,  3.0658e-01],\n",
       "         [-1.3697e+00, -1.0488e-01,  1.1143e+00,  4.9407e-01, -2.8050e-01,\n",
       "           1.9043e-01,  1.0923e+00,  7.8241e-01],\n",
       "         [ 9.8544e-03,  2.8361e+00,  1.3943e+00, -2.6606e+00,  6.1891e-01,\n",
       "           1.7957e-01, -6.4656e-02, -1.3650e+00],\n",
       "         [-1.0270e+00,  2.1041e-01, -1.4908e+00,  1.1860e+00, -6.9193e-01,\n",
       "           2.2204e+00, -2.8075e-01, -9.2363e-01],\n",
       "         [-2.4173e-01,  1.9715e+00,  2.4762e+00, -2.1297e-01,  1.2427e+00,\n",
       "          -1.0278e+00, -3.5004e-01, -8.3363e-01],\n",
       "         [-3.7607e-01, -7.5486e-01,  2.9167e-01, -1.6166e+00,  9.7332e-01,\n",
       "           3.8702e-01, -9.0292e-01,  1.3075e+00],\n",
       "         [ 1.0446e+00, -2.3026e+00, -4.1886e-01,  1.3766e+00, -1.1412e+00,\n",
       "          -9.1974e-01,  1.9908e+00,  7.0328e-01]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q @ k.transpose(-2, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
